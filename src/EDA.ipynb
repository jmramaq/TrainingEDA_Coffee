{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "src_path = os.getcwd()\n",
    "data_path = \"/data/raw/\"\n",
    "data_file = \"merged_data.csv\"\n",
    "\n",
    "file_path= Path(os.path.dirname(src_path)+data_path+data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 44)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1339 entries, 0 to 1338\n",
      "Data columns (total 44 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             1339 non-null   int64  \n",
      " 1   Species                1339 non-null   object \n",
      " 2   Owner                  1332 non-null   object \n",
      " 3   Country.of.Origin      1338 non-null   object \n",
      " 4   Farm.Name              980 non-null    object \n",
      " 5   Lot.Number             276 non-null    object \n",
      " 6   Mill                   1021 non-null   object \n",
      " 7   ICO.Number             1182 non-null   object \n",
      " 8   Company                1130 non-null   object \n",
      " 9   Altitude               1113 non-null   object \n",
      " 10  Region                 1280 non-null   object \n",
      " 11  Producer               1107 non-null   object \n",
      " 12  Number.of.Bags         1339 non-null   int64  \n",
      " 13  Bag.Weight             1339 non-null   object \n",
      " 14  In.Country.Partner     1339 non-null   object \n",
      " 15  Harvest.Year           1292 non-null   object \n",
      " 16  Grading.Date           1339 non-null   object \n",
      " 17  Owner.1                1332 non-null   object \n",
      " 18  Variety                1113 non-null   object \n",
      " 19  Processing.Method      1169 non-null   object \n",
      " 20  Aroma                  1339 non-null   float64\n",
      " 21  Flavor                 1339 non-null   float64\n",
      " 22  Aftertaste             1339 non-null   float64\n",
      " 23  Acidity                1339 non-null   float64\n",
      " 24  Body                   1339 non-null   float64\n",
      " 25  Balance                1339 non-null   float64\n",
      " 26  Uniformity             1339 non-null   float64\n",
      " 27  Clean.Cup              1339 non-null   float64\n",
      " 28  Sweetness              1339 non-null   float64\n",
      " 29  Cupper.Points          1339 non-null   float64\n",
      " 30  Total.Cup.Points       1339 non-null   float64\n",
      " 31  Moisture               1339 non-null   float64\n",
      " 32  Category.One.Defects   1339 non-null   int64  \n",
      " 33  Quakers                1338 non-null   float64\n",
      " 34  Color                  1121 non-null   object \n",
      " 35  Category.Two.Defects   1339 non-null   int64  \n",
      " 36  Expiration             1339 non-null   object \n",
      " 37  Certification.Body     1339 non-null   object \n",
      " 38  Certification.Address  1339 non-null   object \n",
      " 39  Certification.Contact  1339 non-null   object \n",
      " 40  unit_of_measurement    1339 non-null   object \n",
      " 41  altitude_low_meters    1109 non-null   float64\n",
      " 42  altitude_high_meters   1109 non-null   float64\n",
      " 43  altitude_mean_meters   1109 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(24)\n",
      "memory usage: 460.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">ANALIZANDO EL DATASET</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset consta de 1339 filas por 44 columnas y contiene la información relativa a diferentes variedades de café de tipo Arabica y Robusta revisada por personal del CQI (Coffee Quality Institute).\n",
    "\n",
    "La información se divide en:\n",
    "\n",
    "Calidad de café (Cupping Score)\n",
    "- Aroma\n",
    "- Flavor\n",
    "- Aftertaste\n",
    "- Acidity\n",
    "- Body\n",
    "- Balance\n",
    "- Uniformity\n",
    "- Clean Cup\n",
    "- Sweetness\n",
    "\n",
    "\n",
    "Semilla (Bean)\n",
    "- Species (arabica / robusta)\n",
    "- Variety\n",
    "- Processing Method\n",
    "- Moisture\n",
    "- Color\n",
    "- Category.One.Defects\n",
    "- Category.Two.Defects\n",
    "- Quakers\n",
    "\n",
    "\n",
    "Plantación (Farm)\n",
    "- Country.of.Origin\n",
    "- Farm.Name\n",
    "- Mill\n",
    "- Owner\n",
    "- Company\n",
    "- Altitude\n",
    "- Region\n",
    "\n",
    "\n",
    "\n",
    "La columna \"Total Cup Points\" será nuestro medidor de calidad, siendo mejor el café cuanto más alta sea esta puntuación.\n",
    "\n",
    "Realizaremos un análisis univariante y multivariante de todas las variables, con el objetivo final de encontrar un algoritmo que permita predecir qué café tendrá una mejor puntuación en función de sus características.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting columns we don't need to analyze: \"Unnamed\", \"ICO Number\", \"Certification Contact\", \"Certification Address\" and we will use ID as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\", \"ICO Number\", \"Certification Contact\", \"Certification Address\"]).set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates. Can go on with the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values\n",
    "for column in df.columns:\n",
    "    unique_val = df[column].unique()\n",
    "    print(\"Unique values for: {}: {}\".format(column, len(df[column].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null / Missing values\n",
    "df[df.columns[df.isnull().any()]].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the columns with missing values are object type so we replace all nan values with UNKNOWN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"UNKNOWN\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNIVARIANT ANALYSIS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUNTRY OF ORIGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Country of Origin\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to translate or change values in any way, so we can proceed with the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, y=\"Country of Origin\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking values for VARIETY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Variety\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple and different values for unknown varieties or missing values. We will standarize it and assign the value \"UNKNOWN\" for all of them.\n",
    "\n",
    "Also, we will replace the '+' symbols as well as 'and' or 'y' words with commas to correctly separate the coffee varieties.\n",
    "\n",
    "To finish, we will write all the words in capital letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Variety\"][(df[\"Variety\"]=='unknown') | (df[\"Variety\"]=='unknow')] = \"UNKNOWN\"\n",
    "df.loc[df[\"Variety\"].str.contains(' \\+ '), 'Variety'] = df[\"Variety\"].str.replace(' + ',',')\n",
    "df.loc[df[\"Variety\"].str.contains('\\+'), 'Variety'] = df[\"Variety\"].str.replace('+',',')\n",
    "df.loc[df[\"Variety\"].str.contains(' and '), 'Variety'] = df[\"Variety\"].str.replace(' and ',',')\n",
    "df.loc[df[\"Variety\"].str.contains(' Y '), 'Variety'] = df[\"Variety\"].str.replace(' Y ',',')\n",
    "df.loc[df[\"Variety\"].str.contains(' & '), 'Variety'] = df[\"Variety\"].str.replace(' & ',',')\n",
    "df[\"Variety\"] = df[\"Variety\"].str.upper()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking values for PROCESSING METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Processing Method\"].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the method in spanish for the translated one, which is \"Semi Washed\" and set all values to capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Processing Method\"][(df[\"Processing Method\"]=='SEMI-LAVADO')] = 'Semi Washed'\n",
    "df[\"Processing Method\"] = df[\"Processing Method\"].str.upper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
